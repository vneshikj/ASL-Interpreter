{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"mnistDataset/\"\n",
    "testDf = pd.read_csv(data_dir+\"sign_mnist_test.csv\")\n",
    "trainDf = pd.read_csv(data_dir+\"sign_mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_nparray(train_df, test_df):\n",
    "    train_df1 = train_df.copy(deep = True)\n",
    "    test_df1 = test_df.copy(deep = True)\n",
    "    train_images = train_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n",
    "    test_images = test_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n",
    "    return train_images,test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImage, testImage = dataframe_to_nparray(trainDf,testDf)\n",
    "trainLabels = trainDf['label'].values\n",
    "testLabels = testDf['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- TRANSFORM INTO DATAFRAME -----------\n",
    "trainImagesShaped = trainImage.reshape(trainImage.shape[0],1,28,28) \n",
    "testImagesShaped = testImage.reshape(testImage.shape[0],1,28,28) # 3 dimensional tensors\n",
    "\n",
    "# ------- CONVERT INTO PYTORCH TENSORS -------\n",
    "trainImageTensors = torch.from_numpy(trainImagesShaped)\n",
    "trainLabelTensors = torch.from_numpy(trainLabels)\n",
    "testImageTensors = torch.from_numpy(testImagesShaped)\n",
    "testLabelTensors = torch.from_numpy(testLabels)\n",
    " \n",
    "trainDataFull = TensorDataset(trainImageTensors, trainLabelTensors) # to be divided into train/validation\n",
    "testData = TensorDataset(testImageTensors, testLabelTensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "img, label = trainDataFull[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- HYPER PARAMETERS and other constants -------\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "in_channels = 1\n",
    "input_size = in_channels * 28 * 28\n",
    "num_classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- CREATE TRAINING AND VALIDATION DATASET ----------\n",
    "random_seed = 11\n",
    "torch.manual_seed(random_seed);\n",
    "\n",
    "val_size = 7455\n",
    "train_size = len(trainDataFull)-val_size\n",
    "\n",
    "trainData, valData = random_split(trainDataFull, [train_size, val_size]) # create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainData, batch_size, shuffle=True)\n",
    "valDataLoader = DataLoader(valData, batch_size*2, num_workers=4, pin_memory=True)\n",
    "testDataLoader = DataLoader(testData, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# ------- CREATING NEURAL NETWORK ------\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 2 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(in_size, 512)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        # hidden layer 3\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        # output layer  \n",
    "        self.linear4 = nn.Linear(128, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        out = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer 1\n",
    "        out = self.linear1(out)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get intermediate outputs using hidden layer 2\n",
    "        out = self.linear2(out)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get inermediate outputs using hidden layer 3\n",
    "        out = self.linear3(out)\n",
    "        # Apply a activation function\n",
    "        out = F.relu(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear4(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valueLoader):\n",
    "    outputs = [model.validation_step(batch) for batch in valueLoader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, trainLoader, valueLoader, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in trainLoader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        result = evaluate(model,valueLoader)\n",
    "        model.epoch_end(epoch,result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device, non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_size, out_size = num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = to_device(model,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 11.211682319641113, 'val_acc': 0.03898134082555771}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, valData)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 2.9397, val_acc: 0.2180\n",
      "Epoch [1], val_loss: 1.3594, val_acc: 0.5537\n",
      "Epoch [2], val_loss: 1.1234, val_acc: 0.6340\n",
      "Epoch [3], val_loss: 0.6022, val_acc: 0.8303\n",
      "Epoch [4], val_loss: 0.4660, val_acc: 0.8549\n",
      "Epoch [5], val_loss: 0.3332, val_acc: 0.9142\n",
      "Epoch [6], val_loss: 0.2536, val_acc: 0.9409\n",
      "Epoch [7], val_loss: 0.1958, val_acc: 0.9517\n",
      "Epoch [8], val_loss: 0.1248, val_acc: 0.9831\n",
      "Epoch [9], val_loss: 0.0924, val_acc: 0.9885\n"
     ]
    }
   ],
   "source": [
    "history += fit(10, 0.001, model, trainData, valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6 , Predicted: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------- PREDICTING IMAGES -------------\n",
    "def predict_image(image, model):\n",
    "    xb = to_device(image.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "image, label = testData[70]\n",
    "plt.imshow(image.view(28,28),cmap='gray')\n",
    "print('Label:', label.item(), ', Predicted:', predict_image(image, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
